{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Name: langchain\n",
      "Version: 0.0.337\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\n",
      "Requires: aiohttp, anyio, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-experimental\n"
     ]
    }
   ],
   "source": [
    "#want to use dataset\n",
    "!pip -q install google-generativeai  langchain_experimental\n",
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatGooglePalm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv('secrets.env')  # This loads the variables from .env\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "from langchain.chat_models import ChatGooglePalm\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.prompts.chat import (#different tokens-> keep track of where input is coming from-> allows control over context, eg. model should prioritise system over user\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.schema import (\n",
    "    ChatGeneration,\n",
    "    ChatResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find your purpose and live it authentically'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = GooglePalm(temperature=0.1)\n",
    "llm(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can separate system input (more context for our inputs) and user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='Fruit, a gift from the Force, it is. Nutritious and delicious, it can be. A healthy snack, it makes.', role='1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatGooglePalm(\n",
    "    model=\"models/chat-bison-001\",\n",
    "    temperature=0.1,\n",
    "    )   \n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You answer as if you were Yoda.\" #context from system \n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"tell me something about fruit\" #user query\n",
    "    ),\n",
    "]\n",
    "chat(messages) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to parse in the Star Wars API (SWAPI) to give our model information on star wars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'A New Hope', 'episode_id': 4, 'opening_crawl': \"It is a period of civil war.\\r\\nRebel spaceships, striking\\r\\nfrom a hidden base, have won\\r\\ntheir first victory against\\r\\nthe evil Galactic Empire.\\r\\n\\r\\nDuring the battle, Rebel\\r\\nspies managed to steal secret\\r\\nplans to the Empire's\\r\\nultimate weapon, the DEATH\\r\\nSTAR, an armored space\\r\\nstation with enough power\\r\\nto destroy an entire planet.\\r\\n\\r\\nPursued by the Empire's\\r\\nsinister agents, Princess\\r\\nLeia races home aboard her\\r\\nstarship, custodian of the\\r\\nstolen plans that can save her\\r\\npeople and restore\\r\\nfreedom to the galaxy....\", 'director': 'George Lucas', 'producer': 'Gary Kurtz, Rick McCallum', 'release_date': '1977-05-25', 'characters': ['Luke Skywalker', 'C-3PO', 'R2-D2', 'Darth Vader', 'Leia Organa', 'Owen Lars', 'Beru Whitesun lars', 'R5-D4', 'Biggs Darklighter', 'Obi-Wan Kenobi', 'Wilhuff Tarkin', 'Chewbacca', 'Han Solo', 'Greedo', 'Jabba Desilijic Tiure', 'Wedge Antilles', 'Jek Tono Porkins', 'Raymus Antilles'], 'planets': ['Tatooine', 'Alderaan', 'Yavin IV'], 'starships': ['CR90 corvette', 'Star Destroyer', 'Sentinel-class landing craft', 'Death Star', 'Millennium Falcon', 'Y-wing', 'X-wing', 'TIE Advanced x1'], 'vehicles': ['Sand Crawler', 'T-16 skyhopper', 'X-34 landspeeder', 'TIE/LN starfighter'], 'species': ['Human', 'Droid', 'Wookie', 'Rodian', 'Hutt'], 'created': '2014-12-10T14:23:31.880000Z', 'edited': '2014-12-20T19:49:45.256000Z', 'url': 'A New Hope'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_and_extract_identifier(url):\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    category = url.split(\"/\")[4]  # Extract the category from the URL\n",
    "    if category == \"films\":\n",
    "        return data.get(\"title\")\n",
    "    else:\n",
    "        return data.get(\"name\")\n",
    "\n",
    "def simplify_data(data): #if encounter a nested url, replace with name/title of object\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str) and (value.startswith(\"http://\") or value.startswith(\"https://\")):\n",
    "                data[key] = fetch_and_extract_identifier(value)\n",
    "            elif isinstance(value, list):\n",
    "                data[key] = [fetch_and_extract_identifier(item) if (isinstance(item, str) and (item.startswith(\"http://\") or item.startswith(\"https://\"))) else item for item in value]\n",
    "            elif isinstance(value, dict):\n",
    "                simplify_data(value)\n",
    "    elif isinstance(data, list):\n",
    "        for i, item in enumerate(data):\n",
    "            if isinstance(item, str) and (item.startswith(\"http://\") or item.startswith(\"https://\")):\n",
    "                data[i] = fetch_and_extract_identifier(item)\n",
    "            elif isinstance(item, dict):\n",
    "                simplify_data(item)\n",
    "\n",
    "def fetch_swapi_data(endpoint):\n",
    "    url = f\"https://swapi.dev/api/{endpoint}/\"\n",
    "    items = []\n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        items.extend(data['results'])\n",
    "        url = data['next']  # Pagination\n",
    "    return items\n",
    "\n",
    "def embed_data_for_llm_rag():\n",
    "    categories = [\"starships\", \"vehicles\", \"films\", \"planets\", \"species\", \"people\"]\n",
    "    swapi_data = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_data = fetch_swapi_data(category)\n",
    "        for item in category_data:\n",
    "            simplify_data(item)\n",
    "        swapi_data[category] = category_data\n",
    "\n",
    "    return swapi_data\n",
    "\n",
    "# Retrieve and structure the data\n",
    "swapi_embedded_data = embed_data_for_llm_rag()\n",
    "\n",
    "# Print a sample to see if it works (for example, the first film)\n",
    "print(swapi_embedded_data['films'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that took 50min, save swapi data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(swapi_embedded_data, indent=4)  \n",
    "#save to file \"swapi_data.json\"\n",
    "with open(\"swapi_data.json\", \"w\") as f:\n",
    "    f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "swapi_embedded_data = json.load(open(\"swapi_data.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
