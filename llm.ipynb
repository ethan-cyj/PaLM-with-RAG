{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Name: langchain\n",
      "Version: 0.0.337\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\n",
      "Requires: aiohttp, anyio, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-experimental\n"
     ]
    }
   ],
   "source": [
    "#want to use dataset\n",
    "!pip -q install google-generativeai  langchain_experimental\n",
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatGooglePalm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv('secrets.env')  # This loads the variables from .env\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "from langchain.chat_models import ChatGooglePalm\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.prompts.chat import (#different tokens-> keep track of where input is coming from-> allows control over context, eg. model should prioritise system over user\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.schema import (\n",
    "    ChatGeneration,\n",
    "    ChatResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find your purpose and live it authentically'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = GooglePalm(temperature=0.1)\n",
    "llm(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='Fruit, a gift from the Force, it is. Nutritious and delicious, it can be. A healthy snack, it makes.', role='1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatGooglePalm(\n",
    "    model=\"models/chat-bison-001\",\n",
    "    temperature=0.1,\n",
    "    )   \n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You answer as if you were Yoda.\" #context from system \n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"tell me something about fruit\" #user query\n",
    "    ),\n",
    "]\n",
    "chat(messages) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to parse in the Star Wars API (SWAPI) to give our model information on star wars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 1, 'next': None, 'previous': None, 'results': [{'name': 'Tatooine', 'rotation_period': '23', 'orbital_period': '304', 'diameter': '10465', 'climate': 'arid', 'gravity': '1 standard', 'terrain': 'desert', 'surface_water': '1', 'population': '200000', 'residents': ['https://swapi.dev/api/people/1/', 'https://swapi.dev/api/people/2/', 'https://swapi.dev/api/people/4/', 'https://swapi.dev/api/people/6/', 'https://swapi.dev/api/people/7/', 'https://swapi.dev/api/people/8/', 'https://swapi.dev/api/people/9/', 'https://swapi.dev/api/people/11/', 'https://swapi.dev/api/people/43/', 'https://swapi.dev/api/people/62/'], 'films': ['https://swapi.dev/api/films/1/', 'https://swapi.dev/api/films/3/', 'https://swapi.dev/api/films/4/', 'https://swapi.dev/api/films/5/', 'https://swapi.dev/api/films/6/'], 'created': '2014-12-09T13:50:49.641000Z', 'edited': '2014-12-20T20:58:18.411000Z', 'url': 'https://swapi.dev/api/planets/1/'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def query_swapi(query_type, search_term):\n",
    "    \"\"\"\n",
    "    :param query_type: Type of query (e.g., 'people', 'planets', 'starships').\n",
    "    :param search_term: Search term for the query.\n",
    "    :return: JSON response containing the query results.\n",
    "    \"\"\"\n",
    "    base_url = 'https://swapi.dev/api/'\n",
    "    query_url = f\"{base_url}{query_type}/?search={search_term}\"\n",
    "    \n",
    "    response = requests.get(query_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: Unable to access SWAPI (Status code: {response.status_code})\"\n",
    "\n",
    "# Example usage\n",
    "result = query_swapi('planets', 'tatooine')\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
